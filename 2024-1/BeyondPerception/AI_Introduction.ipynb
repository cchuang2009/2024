{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E8aOC3nS511"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>\n",
        " <a class=\"btnfire small stroke\"><em class=\"fas fa-chevron-circle-down\"></em>\n",
        "    <font size=\"4em\"><font color=\"brown\"> Question, </font></font>\n",
        "  </a>\n",
        "Problem\n",
        "\n",
        "\n",
        "---\n",
        "</summary>\n",
        "\n",
        "Answer"
      ],
      "metadata": {
        "id": "r-A3XMDLUQyJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Open Google colab on Github\n",
        "\n",
        "<big>\n",
        "\n",
        "1. Sign in [Github](https://github.com) and create one's private repository, and upload the colab.\n",
        "2. Visit [Google Research site](https://colab.research.google.com) and select \"GitHub\" to open one's colab file."
      ],
      "metadata": {
        "id": "JJ2X8L3KoQf6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vb9eW2FemauN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comes AI Flood\n",
        "---\n",
        "**Nvidia B200**<br>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1jXef0Zd3f_N2VWeOwkgtvLvspJfDleFR\" width=480 />\n",
        "<br>\n",
        "**Groq LPU**<br>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1hph1_ZoZ6FIQQHz7myMxNJFkY8HEIYTz\" width=480 />\n",
        "<br>\n",
        "**<a href=\"https://cerebras.ai/\">CereBras</a> CD-3**<br>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1SmZczA3YsX-LwakfMi-fPBcI7Kkr_b0_\" width=480 />\n",
        "<br>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NqB-iF3oUAPY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>\n",
        "<big>\n",
        " <a class=\"btnfire small stroke\"><em class=\"fas fa-chevron-circle-down\"></em>\n",
        "    <font size=\"4em\"><font color=\"brown\"> Question, </font></font>\n",
        "  </a>\n",
        "<b>Who is (are) the chip manufacturer(s) above?</b>\n",
        "</big>\n",
        "\n",
        "\n",
        "---\n",
        "</summary>\n",
        "\n",
        "Right,\n",
        "The first and the last, <h3><a href=\"https://www.tsmc.com/english\">\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1HAhiVUxEnzWaKJruNaAW4cKFRk2LENll\" width=400 />\n",
        "</a>\n",
        "\n",
        "<br>\n",
        "Proud of Taiwan!</h3>\n",
        "\n",
        "<br>\n",
        "But the middle selects <h3>\n",
        "<a href=\"https://semiconductor.samsung.com/foundry/\">\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1d4iqZ9joHzpXseKtHRpTnY6roq3pKvZJ\" width=400 />\n",
        "</a>\n",
        "\n",
        "---\n",
        "<p>\n",
        "<details>\n",
        "\n",
        "<p>\n",
        "<summary>\n",
        " <a class=\"btnfire small stroke\"><em class=\"fas fa-chevron-circle-down\"></em>\n",
        "    <font size=\"4em\"><font color=\"brown\"> Question, </font></font>\n",
        "  </a>\n",
        "Why Choose Samsung not TMSC\n",
        "\n",
        "---\n",
        "</summary>\n",
        "\n",
        "\n",
        "<big> Foundry partnership, Process node, Capacity and yield, <font color=\"brown\">Cost</font>,\n"
      ],
      "metadata": {
        "id": "R4AoolORXkns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<big>\n",
        "\n",
        "```\n",
        "火雲邪神:  天下武功，無堅不摧，唯快不破\n",
        "                                    --- 功夫\n",
        "```\n",
        "\n",
        "Concerns\n",
        "---\n",
        "<!-- numbers of Parameters -->\n",
        "1. Speed,\n",
        "2. Size,\n",
        "3. Service Price\n"
      ],
      "metadata": {
        "id": "ZaV1Pusle1Dz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<Big>\n",
        "\n",
        "What, Why, When, Who, How"
      ],
      "metadata": {
        "id": "q55PRJzrmiLT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<big>\n",
        "\n",
        "What\n",
        "---\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1zzUGWYqQtvq7C1mduhh1qOS_VHZPHlw2\" width=600 />\n"
      ],
      "metadata": {
        "id": "Ltm3fchknHGz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>\n",
        " <a class=\"btnfire small stroke\"><em class=\"fas fa-chevron-circle-down\"></em>\n",
        "    <font size=\"4em\"><font color=\"brown\"> Question, </font></font>\n",
        "  </a>\n",
        "When, Progress of LLM\n",
        "\n",
        "\n",
        "---\n",
        "</summary>\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1UJGN97IB79VLgoyJadZp0t1KCXlCcKqb\" width=800 />\n",
        "\n"
      ],
      "metadata": {
        "id": "ivCy2s0SM2GM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>\n",
        " <a class=\"btnfire small stroke\"><em class=\"fas fa-chevron-circle-down\"></em>\n",
        "    <font size=\"4em\"><font color=\"brown\"> Question, </font></font>\n",
        "  </a>\n",
        "Who, behavior to LLM's\n",
        "\n",
        "\n",
        "---\n",
        "</summary>\n",
        "<big>\n",
        "\n",
        "1. LeCun, Meta AI Chief of Meta,\n",
        "<br>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1TFoMhMSV4iza_1V137f3aZLNadYfV3Kd\" width=250 />\n",
        "\n",
        "```\n",
        "LeCun advocating against LLMs;  Don’t work on LLMs;\n",
        "```\n"
      ],
      "metadata": {
        "id": "MWKEu4WQPiDa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference\n",
        "---\n",
        "1. [SambaNova, Cerebras, and Groq Clash Over Token Speed in Wake of OpenAI o1 Launch](https://analyticsindiamag.com/ai-origins-evolution/sambanova-cerebras-and-groq-clash-over-token-speed-in-wake-of-openai-o1-launch/)\n",
        "2. [LeCun's Talk](https://analyticsindiamag.com/ai-news-updates/yann-lecun-advices-students-getting-into-ai-space-to-not-work-on-llms/)\n",
        "\n"
      ],
      "metadata": {
        "id": "jHSMpt_kGnx3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Facts\n",
        "---"
      ],
      "metadata": {
        "id": "BKJziSO3QGuU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>\n",
        " <a class=\"btnfire small stroke\"><em class=\"fas fa-chevron-circle-down\"></em>\n",
        "    <font size=\"4em\"><font color=\"brown\"> 中央社新聞 </font></font>\n",
        "  </a>\n",
        "<big>由於美國的科技封鎖，中國電子業突飛猛進，可以自行製造 8 奈米晶片的 DUV</big>\n",
        "\n",
        "\n",
        "---\n",
        "</summary>\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=14IkRb0JWKnNQWoaegpSUYZRab4Mt1HCh\" width=800 />\n",
        "\n",
        "\n",
        "<big>\n",
        "\n",
        "From Wikipedia\n",
        "---\n",
        "\n",
        "\n",
        "```\n",
        "7 nm Process  \n",
        "\n",
        "```\n",
        "\n",
        "<big>\n",
        "<table>\n",
        "<th>Calculated Value</th><th>nm</th>\n",
        "<tr><td>Minimum half pitch (Flash, MPU fin, LGAA)</td><td>15</td>\n",
        "<tr><td>Minimum required overlay (OL) (DRAM, Flash, MPU)</td><td>3.6</td></tr>\n",
        "<tr><td>Gate pitch</td><td>54</td></tr>\n",
        "<tr><td>Gate length</td><td>20</td></tr>\n",
        "</table>"
      ],
      "metadata": {
        "id": "pv4JURM8tJge"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using LLM\n",
        "==="
      ],
      "metadata": {
        "id": "rG4WJasatDFe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary>\n",
        "<Big>\n",
        "<font size=\"4em\">\n",
        " <a class=\"btnfire small stroke\"><em class=\"fas fa-chevron-circle-down\"></em>\n",
        "    <a href=\"https://cerebras.ai\">[cerebras]</a>:\n",
        "  </a>Create `Upload` app with 2 inputs, one for sequence number ond for `pdf` file upload; list if successful.  \n",
        "</big>\n",
        "\n",
        "---\n",
        "</summary>\n",
        "\n",
        "<Big>\n",
        "<font size=\"4em\">\n",
        "<ol>\n",
        "<li> created but not satisfied!\n",
        "<li> specify the package, and `debug`\n",
        "<li> Upload <a href=\"http://120.126.22.75:8501\">Homework, Using LLM</a>\n",
        "\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "5A0-XFw8QAwV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "giM_OZVStJG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2BoR5RfMVSNQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}